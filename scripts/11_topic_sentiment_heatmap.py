import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from bertopic import BERTopic
from sentence_transformers import SentenceTransformer

# ==========================
# ì„¤ì •
# ==========================
INPUT_PATH = "../data/naver_board_kospi100_with_sentiment.csv"
OUT_DIR = "../results/topic_sentiment_heatmap"
os.makedirs(OUT_DIR, exist_ok=True)

# íˆíŠ¸ë§µì— ë„£ì„ ì¢…ëª© ìˆ˜/í† í”½ ìˆ˜(ë„ˆë¬´ í¬ë©´ ë³´ê¸° ì§€ì €ë¶„)
TOP_TICKERS = 10          # ëŒ“ê¸€ ë§ì€ ì¢…ëª© ê¸°ì¤€ ìƒìœ„ Nê°œ
TOPICS_PER_TICKER = 8     # ê° ì¢…ëª©ì—ì„œ í‘œì‹œí•  í† í”½ ìˆ˜(ë¹ˆë„ ìƒìœ„)
MIN_DOCS_TICKER = 80      # ì¢…ëª©ë³„ ìµœì†Œ ë¬¸ì„œ ìˆ˜(ì ìœ¼ë©´ ìŠ¤í‚µ)

plt.rcParams["axes.unicode_minus"] = False
try:
    plt.rcParams["font.family"] = "Malgun Gothic"
except:
    pass

def safe_filename(name: str) -> str:
    name = re.sub(r"[\\/:*?\"<>|]", "_", str(name))
    return name[:80]

def find_sentiment_col(df):
    cand = [c for c in df.columns if "sentiment" in c.lower()]
    if cand:
        return cand[-1]
    if "label" in df.columns:
        return "label"
    raise KeyError("âŒ sentiment ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

def normalize_sentiment(series: pd.Series) -> pd.Series:
    s = pd.to_numeric(series, errors="coerce")
    uniq = set(pd.unique(s.dropna()))
    if uniq.issubset({0, 1}):
        s = s.map({0: -1, 1: 1})
    return s

def save_fig(path):
    plt.tight_layout()
    plt.savefig(path, dpi=220)
    plt.close()

def plot_heatmap(mat: pd.DataFrame, title: str, filename: str):
    # mat: index=topic_label, columns=ticker
    plt.figure(figsize=(max(10, 1.2*len(mat.columns)), max(6, 0.5*len(mat.index))))
    plt.imshow(mat.values, aspect="auto")
    plt.title(title)
    plt.xticks(range(len(mat.columns)), mat.columns, rotation=45, ha="right")
    plt.yticks(range(len(mat.index)), mat.index)
    plt.colorbar()
    save_fig(os.path.join(OUT_DIR, filename))

def main():
    df = pd.read_csv(INPUT_PATH, encoding="utf-8")
    if "ì¢…ëª©ëª…" not in df.columns:
        raise KeyError("âŒ 'ì¢…ëª©ëª…' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    if "ì œëª©_ì „ì²˜ë¦¬" not in df.columns:
        raise KeyError("âŒ 'ì œëª©_ì „ì²˜ë¦¬' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    sent_col = find_sentiment_col(df)
    df["_sent"] = normalize_sentiment(df[sent_col])
    df = df.dropna(subset=["_sent"]).copy()

    # ë¶„ì„í•  ì¢…ëª© ì„ íƒ: ëŒ“ê¸€ ìˆ˜ ë§ì€ TOP N
    ticker_counts = df["ì¢…ëª©ëª…"].value_counts()
    tickers = [t for t in ticker_counts.head(TOP_TICKERS).index if ticker_counts[t] >= MIN_DOCS_TICKER]

    print("ë¶„ì„ ì¢…ëª©:", tickers)
    if len(tickers) == 0:
        raise ValueError("âŒ ì¡°ê±´(MIN_DOCS_TICKER ë“±) ë•Œë¬¸ì— ë¶„ì„í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    embed_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    # íˆíŠ¸ë§µìš© í–‰ì„ ë§Œë“¤ê¸° ìœ„í•´ â€œTopicLabelâ€ì„ í†µì¼ëœ í˜•íƒœë¡œ ë§Œë“¤ì:
    # ì˜ˆ) "T0(ì‹¤ì /í˜¸ì¬)" ê°™ì€ ë¬¸ìì—´
    all_rows_score = []   # í‰ê·  ê°ì„±(-1~1)
    all_rows_pos = []     # ê¸ì •ë¹„ìœ¨(0~1)
    all_topic_tables = [] # í† í”½ ìš”ì•½ í…Œì´ë¸”(ë³´ê³ ì„œ/ë¶€ë¡ìš©)

    for ticker in tickers:
        sub = df[df["ì¢…ëª©ëª…"] == ticker].copy()
        if len(sub) < MIN_DOCS_TICKER:
            continue

        docs = sub["ì œëª©_ì „ì²˜ë¦¬"].astype(str).tolist()
        sent = sub["_sent"].astype(int).tolist()

        print(f"\n=== {ticker} BERTopic í•™ìŠµ ì¤‘ (n={len(docs)}) ===")
        embeddings = embed_model.encode(docs, show_progress_bar=False)

        topic_model = BERTopic(language="multilingual")
        topics, probs = topic_model.fit_transform(docs, embeddings)

        tmp = pd.DataFrame({
            "doc": docs,
            "sent": sent,
            "topic": topics
        })

        # -1 í† í”½(ì•„ì›ƒë¼ì´ì–´)ì€ ì œì™¸í•˜ë©´ ë³´ê¸° ì¢‹ì•„ì§
        tmp = tmp[tmp["topic"] != -1].copy()
        if len(tmp) == 0:
            print("  â›” ìœ íš¨ í† í”½ì´ ê±°ì˜ ì—†ì–´ ìŠ¤í‚µ")
            continue

        # í† í”½ë³„ í†µê³„
        agg = tmp.groupby("topic").agg(
            n=("sent", "size"),
            mean_sent=("sent", "mean"),
            pos_ratio=("sent", lambda x: (x == 1).mean())
        ).reset_index()

        # ë¹ˆë„ ìƒìœ„ TOPICS_PER_TICKERë§Œ ì‚¬ìš©
        agg = agg.sort_values("n", ascending=False).head(TOPICS_PER_TICKER).copy()

        # í† í”½ í‚¤ì›Œë“œ ì¶”ì¶œí•´ì„œ ë¼ë²¨ ìƒì„±
        topic_labels = []
        top_words_list = []
        for tid in agg["topic"].tolist():
            words = [w for (w, _) in topic_model.get_topic(tid)][:5]
            top_words_list.append(", ".join(words))
            # ì§§ê²Œ 2ê°œ ë‹¨ì–´ë§Œ ë¼ë²¨ì—
            short = "/".join(words[:2]) if len(words) >= 2 else (words[0] if words else "topic")
            topic_labels.append(f"{ticker} | T{tid}({short})")

        agg["topic_label"] = topic_labels
        agg["top_words"] = top_words_list
        agg["ticker"] = ticker

        all_topic_tables.append(agg[["ticker", "topic", "topic_label", "n", "mean_sent", "pos_ratio", "top_words"]])

        # íˆíŠ¸ë§µìš© row êµ¬ì„±
        for _, r in agg.iterrows():
            all_rows_score.append({
                "topic_label": r["topic_label"],
                "ticker": ticker,
                "value": float(r["mean_sent"])
            })
            all_rows_pos.append({
                "topic_label": r["topic_label"],
                "ticker": ticker,
                "value": float(r["pos_ratio"])
            })

        # ì¢…ëª©ë³„ í† í”½ ìš”ì•½ CSV ì €ì¥
        out_csv = os.path.join(OUT_DIR, f"{safe_filename(ticker)}_topic_sentiment_table.csv")
        agg.to_csv(out_csv, index=False, encoding="utf-8-sig")
        print("  âœ… ì €ì¥:", out_csv)

    # ==========================
    # ì „ì²´ íˆíŠ¸ë§µ ë§Œë“¤ê¸°
    # ==========================
    score_df = pd.DataFrame(all_rows_score)
    pos_df = pd.DataFrame(all_rows_pos)

    if len(score_df) == 0:
        raise ValueError("âŒ íˆíŠ¸ë§µì„ ë§Œë“¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í† í”½ ìƒì„± ì‹¤íŒ¨/ìŠ¤í‚µ)")

    score_mat = score_df.pivot_table(index="topic_label", columns="ticker", values="value", aggfunc="mean")
    pos_mat = pos_df.pivot_table(index="topic_label", columns="ticker", values="value", aggfunc="mean")

    # NaNì€ 0ìœ¼ë¡œ ì±„ì›Œì„œ í‘œì‹œ(í•´ë‹¹ ì¢…ëª©ì— ì—†ëŠ” í† í”½)
    score_mat = score_mat.fillna(0)
    pos_mat = pos_mat.fillna(0)

    plot_heatmap(score_mat, "Topic Ã— í‰ê·  ê°ì„±(Mean Sentiment)", "01_heatmap_topic_mean_sent.png")
    plot_heatmap(pos_mat, "Topic Ã— ê¸ì •ë¹„ìœ¨(Pos Ratio)", "02_heatmap_topic_pos_ratio.png")

    # ==========================
    # ì „ì²´ í† í”½ í…Œì´ë¸” í•©ì¹˜ê¸°(ë¶€ë¡ìš©)
    # ==========================
    full_table = pd.concat(all_topic_tables, axis=0, ignore_index=True)
    full_out = os.path.join(OUT_DIR, "topic_sentiment_full_table.csv")
    full_table.to_csv(full_out, index=False, encoding="utf-8-sig")
    print("\nâœ… ì „ì²´ í† í”½-ê°ì„± í…Œì´ë¸” ì €ì¥:", full_out)

    # ì¶”ê°€: í‰ê·  ê°ì„± TOP/BOTTOM 15 ì €ì¥
    top15 = full_table.sort_values("mean_sent", ascending=False).head(15)
    bot15 = full_table.sort_values("mean_sent", ascending=True).head(15)
    top15.to_csv(os.path.join(OUT_DIR, "top15_topics_by_mean_sent.csv"), index=False, encoding="utf-8-sig")
    bot15.to_csv(os.path.join(OUT_DIR, "bottom15_topics_by_mean_sent.csv"), index=False, encoding="utf-8-sig")
    print("âœ… TOP/BOTTOM í† í”½ CSV ì €ì¥ ì™„ë£Œ")

    print("\nğŸ‰ ì™„ë£Œ! ê²°ê³¼ í´ë”:", OUT_DIR)

if __name__ == "__main__":
    main()
