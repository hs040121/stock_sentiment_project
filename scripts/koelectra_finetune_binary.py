import pandas as pd
import numpy as np
import os
from sklearn.utils import shuffle

# =======================================
# ìë™ìœ¼ë¡œ raw í´ë”ì—ì„œ "cleaned" í¬í•¨ëœ CSV ì°¾ê¸°
# =======================================
RAW_DIR = "../data/raw"

def find_cleaned_file():
    for f in os.listdir(RAW_DIR):
        if "cleaned" in f and f.endswith(".csv"):
            return os.path.join(RAW_DIR, f)
    raise FileNotFoundError("âŒ raw í´ë”ì—ì„œ 'cleaned' í¬í•¨ëœ CSVë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

INPUT_PATH = find_cleaned_file()
FULL_OUTPUT = os.path.join(RAW_DIR, "naver_board_kospi100_labeled_full_17k.csv")
BALANCED_OUTPUT = os.path.join(RAW_DIR, "balanced_2000_binary_dataset.csv")

TEXT_COL = "ì œëª©_ì „ì²˜ë¦¬"

# =======================================
# ê°ì„± í‚¤ì›Œë“œ ì‚¬ì „
# =======================================
POS_STRONG = [
    "ìƒí•œê°€", "ê¸‰ë“±", "í­ë“±", "ë°˜ë“±", "ëŒ€ë°•", "í˜¸ì¬", "ìˆ˜ìµ", "í‘ì",
    "ê¸°ëŒ€", "ì¢‹ë‹¤", "ì¢‹ë„¤", "ê°€ì¦ˆì•„", "ê°€ì", "ìš°ìƒí–¥", "ìƒìŠ¹ì¥",
    "ë¶ˆì¥", "ì¶•í•˜", "ê³ ë§™ë‹¤", "ì‹ ê³ ê°€",
]

NEG_STRONG = [
    "í­ë½", "ê¸‰ë½", "í•˜ë½", "ì¶”ë½", "ì†ì‹¤", "ì†ì ˆ", "ë¬¼ë ¸ë‹¤",
    "ë§í•¨", "ë§í–ˆë‹¤", "íœ´ì§€ì¡°ê°", "ì“°ë ˆê¸°", "ê°œì¡ì£¼", "ì‚¬ê¸°",
    "ê³µë§¤ë„", "ì•…ì¬", "ì§€ì˜¥", "ë©˜ë¶•", "ìµœì•…", "ìƒí", "ì–‘ì•„ì¹˜",
]

POS_WEAK = ["ã…‹ã…‹", "ã…ã…", "^^", "ì´ë“", "ê¸°ë¶„ì¢‹", "ì¢‹êµ¬ë§Œ"]
NEG_WEAK = ["ì™œì´ë˜", "ë­í•˜ëƒ", "ë¯¸ì¹œ", "ê°œíŒ", "ë‹µì´ì—†", "í™˜ì¥", "ìš•ë‚˜ì˜¨ë‹¤"]

# =======================================
# ê°ì„± ë¼ë²¨ í•¨ìˆ˜
# =======================================
def classify_sentiment(text: str) -> int:
    if not isinstance(text, str):
        return -1
    t = text.replace(" ", "")

    pos_hits = sum(1 for w in POS_STRONG if w in t)
    neg_hits = sum(1 for w in NEG_STRONG if w in t)

    if pos_hits > 0 and neg_hits == 0:
        return 1
    if neg_hits > 0 and pos_hits == 0:
        return -1
    if pos_hits > 0 and neg_hits > 0:
        return -1

    if any(w in t for w in POS_WEAK):
        return 1
    if any(w in t for w in NEG_WEAK):
        return -1

    return -1

# =======================================
# ë©”ì¸ ë¡œì§
# =======================================
def main():
    print("ğŸ“Œ ê°ì§€ëœ ì…ë ¥ íŒŒì¼:", INPUT_PATH)

    print("ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = pd.read_csv(INPUT_PATH, encoding="utf-8")

    if TEXT_COL not in df.columns:
        raise KeyError(f"âŒ '{TEXT_COL}' ì»¬ëŸ¼ì´ CSVì— ì—†ìŒ!")

    print("ì „ì²´ í…ìŠ¤íŠ¸ ìˆ˜:", len(df))

    # 1) ì „ì²´ ë¼ë²¨ë§
    print("\nì „ì²´ ê°ì„± ë¼ë²¨ë§ ì¤‘...")
    df["label"] = df[TEXT_COL].apply(classify_sentiment)

    print("\në¼ë²¨ ë¶„í¬:")
    print(df["label"].value_counts())

    df.to_csv(FULL_OUTPUT, index=False, encoding="utf-8-sig")
    print("\nâœ” 17k ë¼ë²¨ë§ ì €ì¥ â†’", FULL_OUTPUT)

    # 2) Balanced 2000 ìƒì„±
    pos_df = df[df["label"] == 1]
    neg_df = df[df["label"] == -1]

    n = min(len(pos_df), len(neg_df), 1000)

    balanced = pd.concat([
        pos_df.sample(n=n, random_state=42),
        neg_df.sample(n=n, random_state=42)
    ])

    balanced = shuffle(balanced, random_state=42)
    balanced = balanced[[TEXT_COL, "label"]]

    balanced.to_csv(BALANCED_OUTPUT, index=False, encoding="utf-8-sig")
    print("\nâœ” Balanced Dataset ì €ì¥ â†’", BALANCED_OUTPUT)
    print(f"(ê¸ì • {n}ê°œ / ë¶€ì • {n}ê°œ)")

    print("\nğŸ‰ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
