import pandas as pd
import numpy as np
import re
from sklearn.utils import shuffle

# =======================================
# íŒŒì¼ ê²½ë¡œ ì„¤ì •
# =======================================
INPUT_PATH = "./data/raw/naver_board_kospi100_cleaned.csv"
FULL_OUTPUT = "../data/naver_board_kospi100_labeled_full_17k.csv"
BALANCED_OUTPUT = "../data/balanced_2000_binary_dataset.csv"

TEXT_COL = "ì œëª©_ì „ì²˜ë¦¬"

# =======================================
# ê°ì„± í‚¤ì›Œë“œ ì‚¬ì „
# =======================================
POS_STRONG = [
    "ìƒí•œê°€", "ê¸‰ë“±", "í­ë“±", "ë°˜ë“±", "ëŒ€ë°•", "í˜¸ì¬", "ìˆ˜ìµ", "í‘ì",
    "ê¸°ëŒ€", "ì¢‹ë‹¤", "ì¢‹ë„¤", "ê°€ì¦ˆì•„", "ê°€ì", "ìš°ìƒí–¥", "ìƒìŠ¹ì¥",
    "ë¶ˆì¥", "ì¶•í•˜", "ì¶•í•˜í•©ë‹ˆë‹¤", "ê³ ë§™ë‹¤", "ê³ ë§ˆì›Œ", "ì‹ ê³ ê°€",
]

NEG_STRONG = [
    "í­ë½", "ê¸‰ë½", "í•˜ë½", "ì¶”ë½", "ì†ì‹¤", "ì†ì ˆ", "ë¬¼ë ¸ë‹¤",
    "ë§í•¨", "ë§í–ˆë‹¤", "íœ´ì§€ì¡°ê°", "ì“°ë ˆê¸°", "ê°œì¡ì£¼", "ì‚¬ê¸°",
    "ê³µë§¤ë„", "ì•…ì¬", "ì§€ì˜¥", "ë©˜ë¶•", "ìµœì•…", "ì–‘ì•„ì¹˜",
    "ìƒí", "ìƒì¥íì§€", "êµ­ì¥ì“°ë ˆê¸°", "ê±°ì§€ê°™", "ì£½ì—ˆë‹¤",
]

POS_WEAK = [
    "ã…‹ã…‹", "ã…ã…", "^^", "ì´ë“", "ì´ë“ë´¤ë‹¤", "ê¸°ë¶„ì¢‹", "ì¢‹êµ¬ë§Œ", "ì˜¤ëŠ˜ì€ì›ƒëŠ”ë‹¤"
]

NEG_WEAK = [
    "ì™œì´ë˜", "ë­í•˜ëƒ", "ë­ëƒ", "ì–´ì´ì—†", "ë¯¸ì¹œ", "ê°œíŒ", "ë‹µì´ì—†",
    "ë§í•œê±°", "ì§•ê·¸ëŸ½", "ë‚˜ë¼ë§í–ˆ", "í™˜ì¥", "ìš•ë‚˜ì˜¨ë‹¤"
]

# =======================================
# ê°ì„± ë¼ë²¨ í•¨ìˆ˜ (-1 ë¶€ì • / 1 ê¸ì •)
# =======================================
def classify_sentiment(text: str) -> int:
    if not isinstance(text, str):
        return -1

    t = text.replace(" ", "")

    pos_hits = sum(1 for w in POS_STRONG if w in t)
    neg_hits = sum(1 for w in NEG_STRONG if w in t)

    # ê°•í•œ ë‹¨ì–´ ìš°ì„  íŒì •
    if pos_hits > 0 and neg_hits == 0:
        return 1
    if neg_hits > 0 and pos_hits == 0:
        return -1
    if pos_hits > 0 and neg_hits > 0:
        return -1  # ì„ì´ë©´ ë¶€ì •ìœ¼ë¡œ

    # ì•½í•œ ë‹¨ì–´ íŒì •
    if any(w in t for w in POS_WEAK):
        return 1
    if any(w in t for w in NEG_WEAK):
        return -1

    # ì•„ë¬´ê²ƒë„ ì•ˆ ë§ìœ¼ë©´ ì¤‘ë¦½ ì œê±° â†’ ê¸°ë³¸ ë¶€ì •
    return -1

# =======================================
# ë©”ì¸ ë¡œì§
# =======================================
def main():
    print("ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = pd.read_csv(INPUT_PATH, encoding="utf-8")

    if TEXT_COL not in df.columns:
        raise KeyError(f"âŒ '{TEXT_COL}' ì»¬ëŸ¼ì´ CSVì— ì—†ìŒ!")

    print("ì „ì²´ í…ìŠ¤íŠ¸ ìˆ˜:", len(df))

    # -----------------------------
    # 1) ì „ì²´ 17k ë¼ë²¨ë§
    # -----------------------------
    print("\nì „ì²´ ê°ì„± ë¼ë²¨ë§ ì¤‘...")
    df["label"] = df[TEXT_COL].apply(classify_sentiment)

    print("\në¼ë²¨ ë¶„í¬:")
    print(df["label"].value_counts())

    df.to_csv(FULL_OUTPUT, index=False, encoding="utf-8-sig")
    print("\nâœ” ì €ì¥ ì™„ë£Œ â†’", FULL_OUTPUT)

    # -----------------------------
    # 2) Balanced 2000 ìƒì„±
    # -----------------------------
    pos_df = df[df["label"] == 1]
    neg_df = df[df["label"] == -1]

    n = min(len(pos_df), len(neg_df), 1000)

    balanced = pd.concat([
        pos_df.sample(n=n, random_state=42),
        neg_df.sample(n=n, random_state=42)
    ], axis=0)

    balanced = shuffle(balanced, random_state=42)
    balanced = balanced[[TEXT_COL, "label"]]

    balanced.to_csv(BALANCED_OUTPUT, index=False, encoding="utf-8-sig")

    print("\nBalanced Dataset ì €ì¥ ì™„ë£Œ â†’", BALANCED_OUTPUT)
    print(f"(ê¸ì • {n}ê°œ, ë¶€ì • {n}ê°œ, ì´ {len(balanced)}ê°œ)")

    print("\nğŸ‰ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
